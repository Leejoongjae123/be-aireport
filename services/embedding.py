# -*- coding: utf-8 -*-
"""
ë©€í‹°ëª¨ë‹¬ RAG - PyMuPDF + Pytesseract ê¸°ë°˜
Unstructured ëŒ€ì‹  PyMuPDFì™€ Pytesseractë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ONNX Runtime ì˜ì¡´ì„± ì œê±°
"""

import os
import io
import re
import json
import uuid
import base64
from typing import List, Dict, Any, Tuple
from pathlib import Path

import fitz  # PyMuPDF
from PIL import Image
import pytesseract
from pdf2image import convert_from_path

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.stores import InMemoryStore
from langchain_core.documents import Document
from langchain.retrievers import MultiVectorRetriever
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_text_splitters import CharacterTextSplitter


# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def looks_like_base64(sb: str) -> bool:
    """ë¬¸ìì—´ì´ base64ë¡œ ë³´ì´ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return re.match("^[A-Za-z0-9+/]+[=]{0,2}$", sb) is not None


def is_image_data(b64data: str) -> bool:
    """base64 ë°ì´í„°ê°€ ì´ë¯¸ì§€ì¸ì§€ ì‹œì‘ ë¶€ë¶„ì„ ë³´ê³  í™•ì¸í•©ë‹ˆë‹¤."""
    image_signatures = {
        b"\xff\xd8\xff": "jpg",
        b"\x89\x50\x4e\x47\x0d\x0a\x1a\x0a": "png",
        b"\x47\x49\x46\x38": "gif",
        b"\x52\x49\x46\x46": "webp",
    }
    try:
        header = base64.b64decode(b64data)[:8]
        for sig, format in image_signatures.items():
            if header.startswith(sig):
                return True
        return False
    except Exception:
        return False


# Tesseract ê²½ë¡œ ì„¤ì •
import platform

if platform.system() == "Windows":
    tesseract_path = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
    if os.path.exists(tesseract_path):
        pytesseract.pytesseract.tesseract_cmd = tesseract_path
        print(f"âœ… Tesseract ê²½ë¡œ ì„¤ì • ì™„ë£Œ: {tesseract_path}")
else:
    tesseract_path = "/usr/bin/tesseract"
    if os.path.exists(tesseract_path):
        print(f"âœ… Tesseract ê²½ë¡œ í™•ì¸ ì™„ë£Œ: {tesseract_path}")

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
from dotenv import load_dotenv
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def extract_text_and_images_from_pdf(pdf_path: str, output_folder: str) -> Tuple[List[Dict], List[str]]:
    """
    PyMuPDFë¥¼ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        output_folder: ì´ë¯¸ì§€ ì €ì¥ í´ë”
        
    Returns:
        (í…ìŠ¤íŠ¸ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸, ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸)
    """
    print(f"ğŸ“„ PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘: {pdf_path}")
    
    # ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±
    images_folder = os.path.join(output_folder, "images")
    os.makedirs(images_folder, exist_ok=True)
    
    text_elements = []
    image_paths = []
    
    # PyMuPDFë¡œ PDF ì—´ê¸°
    doc = fitz.open(pdf_path)
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = page.get_text()
        if text.strip():
            text_elements.append({
                "type": "text",
                "content": text,
                "page": page_num + 1,
                "metadata": {"source": pdf_path, "page": page_num + 1}
            })
        
        # í˜ì´ì§€ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¡œ ë Œë”ë§ (í˜ì´ì§€ë‹¹ 1ê°œ ì´ë¯¸ì§€)
        try:
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2ë°° í•´ìƒë„
            image_filename = f"page_{page_num + 1}_full.png"
            image_path = os.path.join(images_folder, image_filename)
            pix.save(image_path)
            
            image_paths.append(image_path)
            print(f"  âœ… í˜ì´ì§€ ë Œë”ë§: {image_filename}")
            
        except Exception as e:
            print(f"  âš ï¸  í˜ì´ì§€ ë Œë”ë§ ì‹¤íŒ¨ (page {page_num + 1}): {e}")
    
    doc.close()
    
    # í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš° OCR ìˆ˜í–‰
    if not text_elements or all(not elem["content"].strip() for elem in text_elements):
        print("ğŸ“ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. OCR ìˆ˜í–‰ ì¤‘...")
        text_elements = perform_ocr_on_pdf(pdf_path, output_folder)
    
    print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: í…ìŠ¤íŠ¸ {len(text_elements)}ê°œ, í˜ì´ì§€ ì´ë¯¸ì§€ {len(image_paths)}ê°œ")
    return text_elements, image_paths


def perform_ocr_on_pdf(pdf_path: str, output_folder: str) -> List[Dict]:
    """
    pdf2imageì™€ pytesseractë¥¼ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ OCRì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        output_folder: ì‘ì—… í´ë”
        
    Returns:
        í…ìŠ¤íŠ¸ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
    """
    print("ğŸ” OCR ì²˜ë¦¬ ì‹œì‘...")
    text_elements = []
    
    try:
        # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        images = convert_from_path(pdf_path, dpi=200)
        
        for page_num, image in enumerate(images, start=1):
            # Pytesseractë¡œ OCR ìˆ˜í–‰ (í•œê¸€ + ì˜ì–´)
            text = pytesseract.image_to_string(image, lang='kor+eng')
            
            if text.strip():
                text_elements.append({
                    "type": "text",
                    "content": text,
                    "page": page_num,
                    "metadata": {"source": pdf_path, "page": page_num, "ocr": True}
                })
                print(f"  âœ… OCR ì™„ë£Œ: í˜ì´ì§€ {page_num}")
        
        print(f"âœ… OCR ì²˜ë¦¬ ì™„ë£Œ: {len(text_elements)}ê°œ í˜ì´ì§€")
        
    except Exception as e:
        print(f"âŒ OCR ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    return text_elements


def encode_image_to_base64(image_path: str) -> str:
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def summarize_text_with_gpt(text: str, model: str = "gpt-4o-mini") -> str:
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        text: ìš”ì•½í•  í…ìŠ¤íŠ¸
        model: ì‚¬ìš©í•  GPT ëª¨ë¸
        
    Returns:
        ìš”ì•½ëœ í…ìŠ¤íŠ¸
    """
    prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ì„¸ìš”:

{text}

ìš”ì•½:"""
    
    llm = ChatOpenAI(model=model, temperature=0)
    response = llm.invoke(prompt)
    return response.content


def summarize_image_with_gpt(image_path: str, model: str = "gpt-4o") -> str:
    """
    GPT-4 Visionì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        model: ì‚¬ìš©í•  GPT ëª¨ë¸ (gpt-4o ë˜ëŠ” gpt-4-vision-preview)
        
    Returns:
        ì´ë¯¸ì§€ ì„¤ëª…
    """
    base64_image = encode_image_to_base64(image_path)
    
    llm = ChatOpenAI(model=model, max_tokens=1024, temperature=0)
    
    msg = llm.invoke(
        [
            HumanMessage(
                content=[
                    {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. í…ìŠ¤íŠ¸, ë„í‘œ, ê·¸ë˜í”„ ë“± ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”."},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                    },
                ]
            )
        ]
    )
    return msg.content


def create_text_summaries(texts: List[Dict], summarize: bool = True) -> Tuple[List[str], List[str]]:
    """
    í…ìŠ¤íŠ¸ ìš”ì†Œë“¤ì„ ìš”ì•½í•˜ê³  IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        texts: í…ìŠ¤íŠ¸ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
        summarize: ìš”ì•½ ìˆ˜í–‰ ì—¬ë¶€
        
    Returns:
        (ìš”ì•½ ë¦¬ìŠ¤íŠ¸, ID ë¦¬ìŠ¤íŠ¸)
    """
    text_summaries = []
    text_ids = []
    
    for idx, text_elem in enumerate(texts):
        text_content = text_elem["content"]
        
        if summarize and len(text_content) > 500:
            try:
                summary = summarize_text_with_gpt(text_content)
                text_summaries.append(summary)
                print(f"  âœ… í…ìŠ¤íŠ¸ {idx + 1} ìš”ì•½ ì™„ë£Œ")
            except Exception as e:
                print(f"  âš ï¸  í…ìŠ¤íŠ¸ {idx + 1} ìš”ì•½ ì‹¤íŒ¨: {e}")
                text_summaries.append(text_content[:500] + "...")
        else:
            text_summaries.append(text_content)
        
        text_ids.append(str(uuid.uuid4()))
    
    return text_summaries, text_ids


def create_image_summaries(image_paths: List[str]) -> Tuple[List[str], List[str]]:
    """
    ì´ë¯¸ì§€ë“¤ì„ GPT-4 Visionìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        (ìš”ì•½ ë¦¬ìŠ¤íŠ¸, ID ë¦¬ìŠ¤íŠ¸)
    """
    image_summaries = []
    image_ids = []
    
    for idx, image_path in enumerate(image_paths):
        try:
            summary = summarize_image_with_gpt(image_path)
            image_summaries.append(summary)
            image_ids.append(str(uuid.uuid4()))
            print(f"  âœ… ì´ë¯¸ì§€ {idx + 1} ìš”ì•½ ì™„ë£Œ")
        except Exception as e:
            print(f"  âš ï¸  ì´ë¯¸ì§€ {idx + 1} ìš”ì•½ ì‹¤íŒ¨: {e}")
    
    return image_summaries, image_ids


def create_multi_vector_retriever(
    text_summaries: List[str],
    texts: List[Dict],
    text_ids: List[str],
    image_summaries: List[str],
    image_paths: List[str],
    image_ids: List[str],
    collection_name: str = "multi_modal_rag"
) -> MultiVectorRetriever:
    """
    ë©€í‹°ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        text_summaries: í…ìŠ¤íŠ¸ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        texts: ì›ë³¸ í…ìŠ¤íŠ¸ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
        text_ids: í…ìŠ¤íŠ¸ ID ë¦¬ìŠ¤íŠ¸
        image_summaries: ì´ë¯¸ì§€ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        image_ids: ì´ë¯¸ì§€ ID ë¦¬ìŠ¤íŠ¸
        collection_name: Chroma ì»¬ë ‰ì…˜ ì´ë¦„
        
    Returns:
        MultiVectorRetriever
    """
    print("ğŸ”§ ë©€í‹°ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± ì¤‘...")
    
    # Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = Chroma(
        collection_name=collection_name,
        embedding_function=OpenAIEmbeddings()
    )
    
    # ë¬¸ì„œ ì €ì¥ì†Œ ìƒì„±
    store = InMemoryStore()
    id_key = "doc_id"
    
    # ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
    retriever = MultiVectorRetriever(
        vectorstore=vectorstore,
        docstore=store,
        id_key=id_key,
    )
    
    # í…ìŠ¤íŠ¸ ë¬¸ì„œ ì¶”ê°€
    if text_summaries:
        doc_ids_text = text_ids
        summary_texts = [
            Document(page_content=s, metadata={id_key: doc_ids_text[i]})
            for i, s in enumerate(text_summaries)
        ]
        retriever.vectorstore.add_documents(summary_texts)
        retriever.docstore.mset(list(zip(doc_ids_text, [t["content"] for t in texts])))
        print(f"  âœ… í…ìŠ¤íŠ¸ ë¬¸ì„œ {len(text_summaries)}ê°œ ì¶”ê°€")
    
    # ì´ë¯¸ì§€ ë¬¸ì„œ ì¶”ê°€
    if image_summaries:
        doc_ids_images = image_ids
        summary_images = [
            Document(page_content=s, metadata={id_key: doc_ids_images[i]})
            for i, s in enumerate(image_summaries)
        ]
        retriever.vectorstore.add_documents(summary_images)
        retriever.docstore.mset(list(zip(doc_ids_images, image_paths)))
        print(f"  âœ… ì´ë¯¸ì§€ ë¬¸ì„œ {len(image_summaries)}ê°œ ì¶”ê°€")
    
    print("âœ… ë©€í‹°ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± ì™„ë£Œ")
    return retriever


def process_single_folder_by_name(
    folder_name: str,
    base_data_path: str = "./data",
    summarize_texts: bool = False,
    collection_name: str = None
) -> MultiVectorRetriever:
    """
    í´ë”ëª…ìœ¼ë¡œ PDFë¥¼ ì°¾ì•„ì„œ ì²˜ë¦¬í•˜ê³  ë©€í‹°ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        folder_name: í´ë” ì´ë¦„ (ì˜ˆ: "ì„±ì ì¦ëª…ì„œ2222")
        base_data_path: ê¸°ë³¸ ë°ì´í„° ê²½ë¡œ
        summarize_texts: í…ìŠ¤íŠ¸ ìš”ì•½ ìˆ˜í–‰ ì—¬ë¶€
        collection_name: Chroma ì»¬ë ‰ì…˜ ì´ë¦„
        
    Returns:
        MultiVectorRetriever
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“ í´ë” ì²˜ë¦¬ ì‹œì‘: {folder_name}")
    print(f"{'='*60}\n")
    
    # í´ë” ê²½ë¡œ ì„¤ì •
    folder_path = os.path.join(base_data_path, folder_name)
    if not os.path.exists(folder_path):
        raise FileNotFoundError(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
    
    # PDF íŒŒì¼ ì°¾ê¸°
    pdf_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]
    if not pdf_files:
        raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
    
    pdf_path = os.path.join(folder_path, pdf_files[0])
    print(f"ğŸ“„ PDF íŒŒì¼: {pdf_path}")
    
    # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ
    texts, image_paths = extract_text_and_images_from_pdf(pdf_path, folder_path)
    
    # 2. í…ìŠ¤íŠ¸ ìš”ì•½
    print("\nğŸ“ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘...")
    text_summaries, text_ids = create_text_summaries(texts, summarize=summarize_texts)
    
    # 3. ì´ë¯¸ì§€ ìš”ì•½
    print("\nğŸ–¼ï¸  ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")
    image_summaries, image_ids = create_image_summaries(image_paths)
    
    # 4. ë©€í‹°ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
    if collection_name is None:
        # ChromaëŠ” ì˜ë¬¸ì, ìˆ«ì, ì–¸ë”ìŠ¤ì½”ì–´, í•˜ì´í”ˆë§Œ í—ˆìš©
        # í•œê¸€ ë° íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ê³  embed_id ì‚¬ìš©
        import re
        safe_name = re.sub(r'[^a-zA-Z0-9_-]', '', folder_name)
        if not safe_name or len(safe_name) < 3:
            # ì•ˆì „í•œ ì´ë¦„ì´ ì—†ìœ¼ë©´ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©
            import time
            safe_name = f"collection_{int(time.time())}"
        collection_name = f"rag_{safe_name}"
    
    retriever = create_multi_vector_retriever(
        text_summaries=text_summaries,
        texts=texts,
        text_ids=text_ids,
        image_summaries=image_summaries,
        image_paths=image_paths,
        image_ids=image_ids,
        collection_name=collection_name
    )
    
    print(f"\n{'='*60}")
    print(f"âœ… í´ë” ì²˜ë¦¬ ì™„ë£Œ: {folder_name}")
    print(f"{'='*60}\n")
    
    # ì„±ê³µ ì •ë³´ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    return {
        "success": True,
        "retriever": retriever,
        "text_count": len(text_summaries),
        "image_count": len(image_summaries),
        "collection_name": collection_name
    }


def retrieve_and_generate(query: str, retriever: MultiVectorRetriever, model: str = "gpt-4o") -> str:
    """
    ì¿¼ë¦¬ì— ëŒ€í•´ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        retriever: MultiVectorRetriever
        model: ì‚¬ìš©í•  GPT ëª¨ë¸
        
    Returns:
        ìƒì„±ëœ ë‹µë³€
    """
    print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    
    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    docs = retriever.get_relevant_documents(query, top_k=5)
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_parts = []
    for i, doc in enumerate(docs, 1):
        if isinstance(doc, str):
            if doc.endswith(('.png', '.jpg', '.jpeg')):
                # ì´ë¯¸ì§€ì¸ ê²½ìš°
                context_parts.append(f"[ì´ë¯¸ì§€ {i}]: {doc}")
            else:
                # í…ìŠ¤íŠ¸ì¸ ê²½ìš°
                context_parts.append(f"[ë¬¸ì„œ {i}]:\n{doc}\n")
    
    context = "\n\n".join(context_parts)
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""
    
    # GPTë¡œ ë‹µë³€ ìƒì„±
    llm = ChatOpenAI(model=model, temperature=0)
    response = llm.invoke(prompt)
    
    print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
    return response.content


def load_procedure_json(file_path: str = "./procedure.json") -> Dict:
    """procedure.json íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_all_subsections(procedure_data: Dict) -> List[Dict]:
    """
    procedure.jsonì˜ ëª¨ë“  subsectionsë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        procedure_data: procedure.json ë°ì´í„°
        
    Returns:
        subsections: ëª¨ë“  subsection ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    subsections = []
    
    # procedure.jsonì˜ field_numberì™€ field_name ê°€ì ¸ì˜¤ê¸°
    field_number = procedure_data.get('field_number')
    field_name = procedure_data.get('field_name', '')
    
    for section in procedure_data.get('sections', []):
        section_id = section.get('id')
        section_name = section.get('name')
        
        for subsection in section.get('subsections', []):
            if subsection.get('enabled', True):
                subsections.append({
                    'id': subsection.get('id'),
                    'name': subsection.get('name'),
                    'section_id': section_id,
                    'section_name': section_name,
                    'field_number': field_number,
                    'field_name': field_name,
                    'order': subsection.get('order'),
                    'maxChar': subsection.get('maxChar'),
                    'minChar': subsection.get('minChar')
                })
    
    return subsections


def retrieve_for_subsections(
    retriever: MultiVectorRetriever, 
    subsections: List[Dict], 
    output_dir: str = "./output",
    top_k: int = 3
) -> Dict:
    """
    ê° subsectionì— ëŒ€í•´ retrievalì„ ìˆ˜í–‰í•˜ê³  ê°œë³„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        retriever: MultiVectorRetriever ê°ì²´
        subsections: subsection ì •ë³´ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        top_k: ë°˜í™˜í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’: 3)
        
    Returns:
        summary: ì „ì²´ ì²˜ë¦¬ ìš”ì•½
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\nğŸ“‹ ì´ {len(subsections)}ê°œì˜ subsectionì— ëŒ€í•´ retrieval ìˆ˜í–‰ ì¤‘...\n")
    
    summary = {
        "total_subsections": len(subsections),
        "processed": 0,
        "output_directory": output_dir,
        "subsections": []
    }
    
    for idx, subsection in enumerate(subsections, 1):
        subsection_id = subsection['id']
        subsection_name = subsection['name']
        
        print(f"[{idx}/{len(subsections)}] {subsection_id}: {subsection_name}")
        
        # Retrieval ìˆ˜í–‰ (í…ìŠ¤íŠ¸ ìµœì†Œ ê°œìˆ˜ í™•ë³´ë¥¼ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´)
        try:
            # ì´ë¯¸ì§€ í•„í„°ë§ì„ ê³ ë ¤í•˜ì—¬ top_k * 3 ê°œ ê°€ì ¸ì˜´
            docs = retriever.get_relevant_documents(subsection_name)[:(top_k * 3)]
        except Exception as e:
            print(f"  âš ï¸  Retrieval ì‹¤íŒ¨: {e}")
            continue
        
        # Context ì¶”ì¶œ (í…ìŠ¤íŠ¸ë§Œ, ìµœëŒ€ top_kê°œ)
        contexts = []
        all_contents = []  # ëª¨ë“  ì»¨í…ì¸  ì €ì¥ (í•„í„°ë§ ì „)
        rank = 1
        
        for doc in docs:
            # Document ê°ì²´ì—ì„œ page_content ì¶”ì¶œ
            if hasattr(doc, 'page_content'):
                content = doc.page_content
            elif isinstance(doc, str):
                content = doc
            else:
                content = str(doc)
            
            all_contents.append(content)
            
            # ì´ë¯¸ ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ë¥¼ í™•ë³´í–ˆìœ¼ë©´ ì¤‘ë‹¨
            if len(contexts) >= top_k:
                continue
            
            # ì´ë¯¸ì§€ëŠ” ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì €ì¥
            # base64 ì´ë¯¸ì§€ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ ì œì™¸
            is_base64_image = looks_like_base64(content) and is_image_data(content)
            is_image_path = content.endswith(('.png', '.jpg', '.jpeg', '.gif'))
            
            if not is_base64_image and not is_image_path:
                contexts.append({
                    "rank": rank,
                    "type": "text",
                    "content": content
                })
                rank += 1
        
        # contextsê°€ ë¹„ì–´ìˆìœ¼ë©´ ê°€ì¥ ìœ ì‚¬í•œ ê²ƒ 1ê°œë¼ë„ í¬í•¨
        if len(contexts) == 0 and len(all_contents) > 0:
            print(f"  âš ï¸  í…ìŠ¤íŠ¸ contextê°€ ì—†ì–´ ê°€ì¥ ìœ ì‚¬í•œ ê²°ê³¼ 1ê°œ í¬í•¨")
            contexts.append({
                "rank": 1,
                "type": "text",
                "content": all_contents[0]
            })
        
        # ê° subsectionë³„ë¡œ JSON íŒŒì¼ ì €ì¥
        result_data = {
            "subsection_id": subsection_id,
            "subsection_name": subsection_name,
            "section_id": subsection['section_id'],
            "section_name": subsection['section_name'],
            "field_number": subsection.get('field_number'),
            "field_name": subsection.get('field_name', ''),
            "query": subsection_name,
            "retrieved_count": len(contexts),
            "contexts": contexts
        }
        
        # íŒŒì¼ëª…: subsection_id.json (ì˜ˆ: 1-1.json)
        output_file = os.path.join(output_dir, f"{subsection_id}.json")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"  â†’ {len(contexts)}ê°œ context ì¶”ì¶œ ì™„ë£Œ")
        print(f"  â†’ ì €ì¥: {output_file}\n")
        
        # ìš”ì•½ ì •ë³´ ì¶”ê°€
        summary['subsections'].append({
            "id": subsection_id,
            "name": subsection_name,
            "contexts_count": len(contexts),
            "output_file": output_file
        })
        summary['processed'] += 1
    
    return summary
